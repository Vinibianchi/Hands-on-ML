{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd125c4-923f-4113-8ddd-506801d59345",
   "metadata": {},
   "source": [
    "# Exercícios CAP 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f4d3d-76f2-44b4-9704-6f81bf73e149",
   "metadata": {},
   "source": [
    "1. __Quais são as principais motivações para reduzir a dimensionalidade de um conjunto de dados? E as principais desvantagens?__  \n",
    "__R__: Vantagem: Melhora o desempenho do treinamento, evita overfit por reduzir ruído em alguns casos, e reduz o mal da dimensionalidade.\n",
    "\n",
    "2. __O que é a maldição da dimensionalidade?__  \n",
    "__R__: São o conjunto de dificuldades geradas quando um dataset tem muitos atributos, desse modo, quanto mais atributos mais registros são necessários para criar o modelo. Além disso, muitas dimensões aumentam o risco de overfit e prejudicam o desempenho do modelo.  \n",
    "\n",
    "3. __Depois que a dimensionalidade de um conjunto de dados é reduzida, é possível reverter a operação? Em caso afirmativo, como? Se não, por quê?__  \n",
    "__R__: Não, pois reduzir dimensionalidade implica em akgum grau de perda de informação. Sendo possível apenas gerar um conjunto próximo ao original. \n",
    "\n",
    "4. __A PCA pode ser usada para reduzir a dimensionalidade de um conjunto de dados extremamente não linear?__  \n",
    "__R__: Sim, devido ao kernel trick (kernelPCA).  \n",
    "\n",
    "5. __Vamos supor que você execute a PCA em um conjunto de dados de mil dimensões, definindo a taxa de variância explicada para 95%. Quantas dimensões o conjunto de dados resultante terá?__  \n",
    "__R__: ???\n",
    "\n",
    "\n",
    "6. __Em quais casos você usaria a PCA normal, a PCA incremental, a PCA aleatória ou o kernel PCA?__  \n",
    "__R__: PCA normal para treinamento offline, PCA incrimental para treinamento online e kernelPCA para dados extremamente não lineares ou manifolds  \n",
    "\n",
    "\n",
    "7. __Como você pode avaliar o desempenho de um algoritmo de redução de dimensionalidade no seu conjunto de dados?__  \n",
    "__R__: Pelo erro de reconstrução, que mede a distância quadrada entre o ponto origiral e o projetado.\n",
    "\n",
    "\n",
    "8. __Faz algum sentido encadear dois algoritmos de redução de dimensionalidade diferentes?__ \n",
    "__R__: ?? \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a52f03-28ae-463d-b6f5-3a53b363b88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2586606-9568-4bb2-b957-8ce03bae1969",
   "metadata": {},
   "source": [
    "__9. Carregue o conjunto de dados MNIST (apresentado no Capítulo 3) e o divida em um conjunto de treinamento e um conjunto de testes (deixe as primeiras 60 mil instâncias para treinamento e as 10 mil restantes para testar). Treine um classificador Random Forest no conjunto de dados, veja quanto tempo demora e avalie o modelo resultante no conjunto de testes. Em seguida, use a PCA para reduzir a dimensionalidade do conjunto de dados, com uma taxa de variância explicada de 95%. Agora, treine um classificador Random Forest novo no conjunto de dados reduzido e veja quanto tempo leva. O treinamento foi bem mais rápido? Em seguida, avalie o classificador no conjunto de testes.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bbb070-f37f-4691-9cff-34abfd23f1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "679db428-9f6d-4654-82c4-ec7d5af4f573",
   "metadata": {},
   "source": [
    "__10. Use o t-SNE para reduzir o conjunto de dados MNIST para duas dimensões e plote o resultado com a Matplotlib. Você pode usar um gráfico de dispersão usando dez cores diferentes para representar a classe-alvo de cada imagem. Outra alternativa é substituir cada ponto no gráfico de dispersão pela classe da instância correspondente (um algarismo de 0 a 9) ou até plotar versões reduzidas das próprias imagens dos algarismos (se você plotar todos, a visualização ficará muito desordenada, portanto você deve plotar uma amostra aleatória ou uma instância somente se nenhuma outra instância já tiver sido plotada a uma curta distância). Você deve obter uma boa visualização com clusters de algarismos bem separados. Tente usar outros algoritmos de redução de dimensionalidade, como a PCA, a LLE ou a MDS, e compare as visualizações resultantes.__\n",
    "\n",
    "Géron, Aurélien. Mãos A Obra: Aprendizado De Máquina Com Scikit-Learn, Keras & TensorFlow (p. 356). Alta Books. Edição do Kindle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e47263-6d95-401c-aaae-dc4960053712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a55f7-1953-4cdd-85e8-3096af644dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
